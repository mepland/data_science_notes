{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# TODO \n",
    "import sys,os\n",
    "sys.path.append(os.path.expanduser('~/dtreeviz'))\n",
    "\n",
    "# TODO remove\n",
    "sys.path.append(os.path.expanduser('~/imodels'))\n",
    "\n",
    "########################################################\n",
    "# python\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "norm = scipy.stats.norm\n",
    "import bisect\n",
    "\n",
    "########################################################\n",
    "# figs, xgboost, sklearn\n",
    "import imodels\n",
    "from imodels import FIGSClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# TODO\n",
    "# from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "########################################################\n",
    "# dtreeviz\n",
    "# must follow the package README to properly install all dependencies!\n",
    "\n",
    "from dtreeviz import trees\n",
    "from dtreeviz.models.sklearn_decision_trees import ShadowSKDTree\n",
    "from imodels.tree.viz_utils import extract_sklearn_tree_from_figs\n",
    "\n",
    "########################################################\n",
    "# skompiler\n",
    "from skompiler import skompile\n",
    "\n",
    "########################################################\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.')\n",
    "\n",
    "########################################################\n",
    "# set global rnd_seed for reproducibility\n",
    "rnd_seed = 42\n",
    "np.random.seed(rnd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import * # load plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inline=True # plot inline or to pdf\n",
    "output = './output' # output dir\n",
    "os.makedirs(output, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Generate Random Data\n",
    "Include additive structure that FIGS does well on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_params_all = {'n_samples': int(1e5), 'n_classes': 2, 'shuffle': False, 'shift': 0.0, 'scale': 1.0, 'hypercube': True}\n",
    "\n",
    "mc_params = [\n",
    "    {'n_features': 20, 'n_informative': 6, 'n_redundant': 4, 'n_repeated': 0,\n",
    "     'n_clusters_per_class': 5, 'weights': [0.5], 'flip_y': 0.05, 'class_sep': 0.9},\n",
    "    {'n_features': 10, 'n_informative': 4, 'n_redundant': 2, 'n_repeated': 0,\n",
    "     'n_clusters_per_class': 2, 'weights': [0.7], 'flip_y': 0.1, 'class_sep': 0.9},\n",
    "    {'n_features': 5, 'n_informative': 2, 'n_redundant': 2, 'n_repeated': 0,\n",
    "     'n_clusters_per_class': 2, 'weights': [0.6], 'flip_y': 0.04, 'class_sep': 0.9},\n",
    "]\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "feat_names = []\n",
    "\n",
    "for i_mc_param, mc_param in enumerate(mc_params):\n",
    "    param = {**mc_params_all, **mc_param, 'random_state': rnd_seed+i_mc_param}\n",
    "    X_i, y_i = make_classification(**param)\n",
    "    if X is None:\n",
    "        X = X_i\n",
    "    else:\n",
    "        X = np.concatenate([X, X_i], axis=1)\n",
    "    if y is None:\n",
    "        y = y_i\n",
    "    else:\n",
    "        y = np.logical_and(y, y_i).astype(int)\n",
    "    feat_names += [f'x_{i_mc_param}_{_}' for _ in range(X_i.shape[1])]\n",
    "    del X_i; del y_i;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Train, Validation, and Holdout Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainVal, X_holdout, y_trainVal, y_holdout = train_test_split(X, y, test_size=0.15, random_state=rnd_seed, stratify=y)\n",
    "del X; del y;\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, test_size=0.2, random_state=rnd_seed, stratify=y_trainVal)\n",
    "# del X_trainVal; del y_trainVal;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# FIGS\n",
    "Note we are not using early stopping with FIGS so use `X_trainVal` during training to take advantage of all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_figs = FIGSClassifier(max_rules=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_figs_start = time.time()\n",
    "model_figs.fit(X_trainVal, y_trainVal, feature_names=feat_names);\n",
    "time_figs_end = time.time()\n",
    "print(f'FIGS ran in {time_figs_end-time_figs_start:.0f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_splits_figs(model):\n",
    "    splits = []\n",
    "    for tree_ in model.trees_:\n",
    "        node_counter = iter(range(1, int(1e06)))\n",
    "        def _count_node(node):\n",
    "            if node.left is None:\n",
    "                return\n",
    "            node_id=next(node_counter)\n",
    "            _count_node(node.left)\n",
    "            _count_node(node.right)\n",
    "\n",
    "        _count_node(tree_)\n",
    "        splits.append(next(node_counter)-1)\n",
    "    return sum(splits)\n",
    "\n",
    "n_splits_figs = count_splits_figs(model_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'FIGS used {len(model_figs.trees_)} trees and {n_splits_figs} splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_figs.print_tree(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_figs.plot(fig_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_default = {'max_depth': 6, 'learning_rate': 0.3, 'gamma': 0.0, 'reg_alpha': 0.0, 'reg_lambda': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_setup_params = {\n",
    "    'max_num_boost_rounds': 500, # maximum number of boosting rounds to run / trees to create\n",
    "    'xgb_objective': 'binary:logistic', # objective function for binary classification\n",
    "    'xgb_verbosity': 0, #  The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
    "    'xgb_n_jobs': -1, # Number of parallel threads used to run XGBoost. -1 makes use of all cores in your system\n",
    "    'eval_metric': 'auc', # evaluation metric for early stopping\n",
    "    'early_stopping_rounds': 10, # must see improvement over last num_early_stopping_rounds or will halt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_fit_params = {\n",
    "    'eval_set': [(X_val, y_val)], # data sets to use for early stopping evaluation\n",
    "    'verbose': False, # even more verbosity control\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = xgb.XGBClassifier(n_estimators=fixed_setup_params['max_num_boost_rounds'],\n",
    "                                  objective=fixed_setup_params['xgb_objective'],\n",
    "                                  verbosity=fixed_setup_params['xgb_verbosity'],\n",
    "                                  eval_metric=fixed_setup_params['eval_metric'],\n",
    "                                  early_stopping_rounds=fixed_setup_params['early_stopping_rounds'],\n",
    "                                  random_state=rnd_seed+3, **params_default, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_xgboost_start = time.time()\n",
    "model_xgboost.fit(X_train, y_train, **fixed_fit_params);\n",
    "time_xgboost_end = time.time()\n",
    "print(f'XGBoost ran in {time_xgboost_end-time_xgboost_start:.0f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_xgboost = sum([tree.count('\"split\"') for tree in model_xgboost.get_booster().get_dump(dump_format='json')[0:model_xgboost.best_ntree_limit]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'XGBoost used {model_xgboost.best_ntree_limit} trees and {n_splits_xgboost} splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f'XGBoost used {n_splits_xgboost} splits vs FIGS {n_splits_figs}')\n",
    "    print(f'That is {n_splits_xgboost-n_splits_figs}, or {(n_splits_xgboost-n_splits_figs)/n_splits_figs:.0%}, more splits!')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rocs(model, X, y, best_iteration=False):\n",
    "    if best_iteration:\n",
    "        y_pred = model.predict_proba(X, iteration_range=(0, model.best_iteration+1))[:,1]\n",
    "    else:\n",
    "        y_pred = model.predict_proba(X)[:,1]\n",
    "    y_pred_sorted = sorted(y_pred)\n",
    "\n",
    "    fpr, tpr, thr_of_fpr_tpr = roc_curve(y, y_pred)\n",
    "    n_predicted_positive_of_fpr_tpr = [len(y_pred_sorted) - bisect.bisect_left(y_pred_sorted, _thr) for _thr in thr_of_fpr_tpr]\n",
    "    dfp_eval_fpr_tpr = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thr': thr_of_fpr_tpr, 'n_predicted_positive': n_predicted_positive_of_fpr_tpr})\n",
    "    dfp_eval_fpr_tpr = dfp_eval_fpr_tpr.sort_values(by='thr').reset_index(drop=True)\n",
    "\n",
    "    precision, recall, thr_of_precision_recall = precision_recall_curve(y, y_pred)\n",
    "    thr_of_precision_recall = np.insert(thr_of_precision_recall, 0, [0])\n",
    "    n_predicted_positive_of_precision_recall = [len(y_pred_sorted) - bisect.bisect_left(y_pred_sorted, _thr) for _thr in thr_of_precision_recall]\n",
    "    dfp_eval_precision_recall = pd.DataFrame({'precision': precision, 'recall': recall, 'thr': thr_of_precision_recall, 'n_predicted_positive': n_predicted_positive_of_precision_recall})\n",
    "    dfp_eval_precision_recall['f1'] = 2*(dfp_eval_precision_recall['precision'] * dfp_eval_precision_recall['recall']) / (dfp_eval_precision_recall['precision'] + dfp_eval_precision_recall['recall'])\n",
    "\n",
    "    return {'dfp_eval_fpr_tpr': dfp_eval_fpr_tpr, 'dfp_eval_precision_recall': dfp_eval_precision_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_figs_train = make_rocs(model_figs, X_train, y_train)\n",
    "roc_figs_holdout = make_rocs(model_figs, X_holdout, y_holdout)\n",
    "roc_xgboost_train = make_rocs(model_xgboost, X_train, y_train, best_iteration=True)\n",
    "roc_xgboost_holdout = make_rocs(model_xgboost, X_holdout, y_holdout, best_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_for_roc_dict = {\n",
    "#     {**{'name': 'FIGS_train', 'nname': 'FIGS (Train)', 'c': 'C2', 'ls': '-'}, **roc_},\n",
    "#     {**{'name': 'XGBoost', 'nname': 'XGBoost', 'c': 'black', 'ls': '--'}, **roc_},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_PPV_train = len(np.where(y_train == 1)[0]) / len(y_train) # P / (P + N)\n",
    "pop_PPV_holdout = len(np.where(y_holdout == 1)[0]) / len(y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Standard TPR vs FPR ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_rocs(models_for_roc, m_path=f'{output}/roc_curves', rndGuess=False, inverse_log=False, inline=inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Precision vs Recall ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_rocs(models_for_roc, m_path=f'{output}/roc_curves', rndGuess=False, inverse_log=False, precision_recall=True,\n",
    "#     pop_PPV=pop_PPV, y_axis_params={'min': -0.05}, inline=inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Tree Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_figs_0 = extract_sklearn_tree_from_figs(model_figs, tree_num=0, n_classes=2)\n",
    "sk_figs_0 = ShadowSKDTree(dt_figs_0, X_train, y_train, feat_names, 'y', [0, 1])\n",
    "\n",
    "dt_figs_1 = extract_sklearn_tree_from_figs(model_figs, tree_num=1, n_classes=2)\n",
    "sk_figs_1 = ShadowSKDTree(dt_figs_1, X_train, y_train, feat_names, 'y', [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.colors import color_blind_friendly_colors # mpl_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees.dtreeviz(sk_figs_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees.dtreeviz(sk_figs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees.ctreeviz_leaf_samples(sk_figs_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees.ctreeviz_leaf_samples(sk_figs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_figs_0 = skompile(dt_figs_0.predict_proba, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expr_figs_0.to('sqlalchemy/sqlite', component=1, assign_to='tree_0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(expr_figs_0.to('python/code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_figs_1 = skompile(dt_figs_1.predict_proba, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expr_figs_1.to('sqlalchemy/sqlite', component=1, assign_to='tree_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(expr_figs_1.to('python/code'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBoost\n",
    "Tree 0 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
