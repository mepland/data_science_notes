%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{General Concepts}
\label{ml:general}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluating Performance}
\label{ml:general:eval}

\subsubsection{Confusion Marix}
\label{ml:general:eval:cm}

The confusion matrix is a simple table of the number of actual, or truth, class instances
versus the number of a model's predicted class instances.
A two class example is provided in \cref{table:CM}.
Multi-class confusion matrices are straight forward extensions,
with correctly classified instances appearing along the diagonal.

\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c | c |}
  \multicolumn{2}{c}{} & \multicolumn{2}{c}{\textbf{Actual}} \\ \cline{3-4}
  \multicolumn{1}{c}{} & & Positive & Negative \\ \cline{2-4}
  \multirow{4}{*}{\rotatebox{90}{\textbf{Predicted}}} & \multirow{2}{*}{Positive} & \multirow{2}{*}{TP} & FP \\[-8pt]
   & & & (Type I) \\ \cline{2-4}
   & \multirow{2}{*}{Negative} & FN & \multirow{2}{*}{TN} \\[-8pt]
   & & (Type II) & \\ \cline{2-4}
  \end{tabular}
  \caption{Two class confusion matrix.}
  \label{table:CM}
\end{table}

\subsubsection{TPR \& TNR -- Sensitivity \& Specificity}
\label{ml:general:eval:TPR_TNR}
The true positive rate (TPR) and true negative rate (TNR) are
relatively straight forward to compute and understand, along with their complements,
the false negative rate (FNR) and false positive rate (FPR).

\begin{enumerate}[noitemsep]
\item True positive rate (TPR), \ie sensitivity, recall, hit rate.
\begin{equation} \label{eq:TPR}
\text{TPR} = \frac{\text{TP}}{\text{P}} = \frac{\text{TP}}{\text{TP}+\text{FN}} = 1 - \text{FNR} = P\left(\hat{+} \mid + \right)
\end{equation}

\item True negative rate (TNR), \ie specificity, selectivity.
\begin{equation} \label{eq:TNR}
\text{TNR} = \frac{\text{NP}}{\text{N}} = \frac{\text{TN}}{\text{TN}+\text{FP}} = 1 - \text{FPR} = P\left(\hat{-} \mid - \right)
\end{equation}
\end{enumerate}

% TODO precision vs recall

% TODO cite in text
\begin{figure}
\centering
  \begin{subfigure}[c]{0.48\textwidth}\centering
  \includegraphics[width=\textwidth]{figures/ml/precision_recall.pdf}
  \caption{Precision \& Recall}
  \label{fig:graphical_CM_quantities:precision_recall}
  \end{subfigure}
  ~
  \begin{subfigure}[c]{0.48\textwidth}\centering
  \includegraphics[width=\textwidth]{figures/ml/sensitivity_and_specificity.pdf}
  \caption{Sensitivity \& Specificity}
  \label{fig:graphical_CM_quantities:sensitivity_specificity}
  \end{subfigure}
\caption{
Graphical representation of
precision versus recall, by \href{https://commons.wikimedia.org/wiki/File:Precisionrecall.svg}{Walber},
and
sensitivity versus specificity, by \href{http://en.wikipedia.org/wiki/File:Sensitivity_and_specificity.svg}{FeanDoe}.
}
\label{fig:graphical_CM_quantities}
\end{figure}

% TODO other scores: F1, etc

\subsubsection{ROC Curves}
\label{ml:general:eval:ROC}
% TODO include small figure with TPR vs FPR (better in the upper left), and version with better in lower right

\subsubsection{Selecting a Decision Threshold}
\label{ml:general:eval:decision_threshold}

% include \cref to significance section, if eventually added

In physics we may try to maximize the significance $Z$ of a classifier\footnote{And or
work with the \href{https://en.wikipedia.org/wiki/Neyman\%E2\%80\%93Pearson\_lemma}{Neyman-Pearson framework}.} by
picking an optimal point along the ROC curve to set the decision threshold.
However in data science it is often better to create a payoff matrix of the anticipated
benefits associated with a TP or TN, and costs associated with a FP or FN,
for the particular business case at hand.
The expected value of any decision threshold can quickly be computed
from the payoff matrix elements, $E\left( \hat{A} \mid B\right)$, as

\begin{equation} \label{eq:E_profit}
E\left(\text{profit}\right) = \sum_{A,B} E\left( \hat{A} \mid B\right) P\left(\hat{A} \mid B \right) P\left(B\right),
\end{equation}

\noindent where $A$ and $B$ are any two cases.
The optimal decision threshold can then be found by maximizing $E\left(\text{profit}\right)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bias-Variance Tradeoff}
\label{ml:general:biasVar}
% TODO add graphs too

\begin{enumerate}[noitemsep]
\item Bias: Errors due to a model not learning about relationships between features, \ie underfitting.
\item Variance: Errors due to an overly complex model failing to generalize beyond the training data, \ie overfitting.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gradient Decent}
\label{ml:general:gradDec}
% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Normalization}
\label{ml:general:normalization}
% TODO normalization of input features (for faster training, more equal regularization), batch renormalization in neural networks

\subsubsection{Batch Renormalization}
\label{ml:general:reg:batch_renorm}
% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Loss Functions}
\label{ml:general:loss_Func}

% TODO add more loss functions such as log loss, OLS

\subsubsection{Binary Logistic}
\label{ml:supervised:loss_functions:binary_logistic}

In two class, signal $y=1$ and background $y=0$, classification problems the binary logistic function is an appropriate choice of $L$:

\begin{equation} \label{eq:binary_logistic}
L = \sum_{i} \left[y_{i} \ln\left(1 + \exp(-\yhat_{i})\right) +\left(1-y_{i}\right) \ln\left(1 + \exp(\yhat_{i})\right)\right].
\end{equation}

% TODO add more on the information theory aspect

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Regularization}
\label{ml:general:reg}

Regularization is a method for controlling the variance (overfitting)
of a model by putting constraints on the size of its parameters.
The two main types of regularization are shown in \cref{eq:L1_L2}
and depend on different powers of the norm\footnote{In
the case of OLS linear regression the constant intercept term $\beta_{0}$ is not included in $\norm{\bm{\beta}}$.} of the model parameters $\bm{\beta}$.
In order to treat all features equally, normalization must be used before applying regularization.
A hyperparameter $\lambda$ is included to tune the amount of regularization applied in the objective function,
$\text{obj}\left(\bm{\beta}\right) = L + \Omega$.
As $\lambda$ is increased, it decreases the size the model's coefficients, and thereby its variance (overfitting),
up to a point when the model is unable to adequately train on the available data and the bias (underfitting) begins to grow.

\begin{subequations} \label{eq:L1_L2}
\begin{align}
\Omega_{\text{L1}}\left(\bm{\beta}\right) &= \lambda \norm{\bm{\beta}}\,,     \label{eq:L1} \\
\Omega_{\text{L2}}\left(\bm{\beta}\right) &= \lambda \norm{\bm{\beta}}^{2}\,. \label{eq:L2}
\end{align}
\end{subequations}

For a particular value of $\lambda$, the effect of L1 and L2 regularization
is to constrain $\norm{\bm{\beta}}^{q} \leq t\left(\lambda\right)$ for some $t\left(\lambda\right)$.
As can be seen in \cref{fig:ml:l1l2} the L1 norm constrains $\bm{\beta}$ to lie within a hypercube,
while the L2 constraint is a hypersphere.

% TODo replace with split up pdfs from figure 3.11 on page 71 (90 in pdf) of ESLII
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figures/ml/l1l2.png}
\caption{
A graphical representation of the L1 and L2 regularization constraints on $\bm{\beta}$ \cite{HastieTF09}.
The best value of $\bm{\beta}$ for optimizing the loss function $L$ is indicated as $\hat{\bm{\beta}}$.
For a given contour in $L$, L1 will tend to force $\bm{\beta}$ along one of the axes,
identically setting some $\beta_{i}$ coefficients to zero,
while L2 is rotationally symmetric and has no such tendencies.
}
\label{fig:ml:l1l2}
\end{figure}

\subsubsection{L1 -- LASSO}
\label{ml:general:reg:L1}
L1, or LASSO\footnote{Least absolute shrinkage and selection operator.},
regression uses the norm $\norm{\bm{\beta}}$ \cref{eq:L1}, or taxi cab distance.
As it's geometric constraints on $\bm{\beta}$ are hypercubes,
it tends to set some model parameters to 0, creating sparsity,
and thereby acts as a form of built-in feature selection.

\subsubsection{L2 -- Ridge}
\label{ml:general:reg:L2}
L2, or ridge, regression \cref{eq:L2} uses the square of the norm, or euclidean distance.
Models made with L2 regularization are somewhat less interpretable than those made with L1,
as L2 may make many parameters very small, but does not remove them entirely.
The parameters are still shrunk toward zero, and each other,
while highly correlated features are effectively averaged.
L2 is slightly faster to run than L1 computationally as, unlike L1, it
is not represented as a piecewise function and has a closed form expression.

\subsubsection{Elastic Net}
\label{ml:general:reg:EN}

L1 and L2 regularization can be used in combination
to take advantage of both of their benefits.
Such a combination is known as the elastic net penalty \cref{eq:elastic_net},
where the combination can be controlled via two $\lambda_{1}$, $\lambda_{2}$ hyperparameters,
or a shared $\lambda$ and mixing parameter $\alpha$.

\begin{equation} \label{eq:elastic_net}
\begin{split}
\Omega_{\text{EN}}\left(\bm{\beta}\right) &= \lambda_{1} \norm{\bm{\beta}} + \lambda_{2} \norm{\bm{\beta}}^{2}\\
&= \lambda \left( \alpha\norm{\bm{\beta}} + \left(1-\alpha\right)\norm{\bm{\beta}}^{2} \right)
\end{split}
\end{equation}

% TODo connections to SVM (https://en.wikipedia.org/wiki/Elastic_net_regularization#Reduction_to_support_vector_machine)

\subsubsection{Drop Out}
\label{ml:general:reg:Drop}
% TODO

\subsubsection{Early Stopping}
\label{ml:general:reg:early_stopping}
% TODO nice figure on page 38 (57 in pdf) of ESLII
